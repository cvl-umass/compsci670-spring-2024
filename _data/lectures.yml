- date: 2/1
  lecturer: Grant
  title: >
    <strong>Introduction and logistics</strong>
  logistics:
    <span class="deadline">Setup Piazza, Gradescope</span>
  readings:
   - Szeliski book, Chapter 1
   - <a href="https://www.cs.princeton.edu/courses/archive/spring08/cos598B/Readings/ThorpeFizeMarlot1996.pdf">The speed of processing in the human visual system</a>, Thorpe et al., 1996

- title: "Module 1: Image Formation and Representation"

- date: 2/6
  lecturer: Grant
  title: <strong>Radiometry</strong>
  readings:
   - <a href="http://persci.mit.edu/pub_pdfs/dror_sctv_01.pdf">Surface reflectance estimation and natural illumination statistics</a>, Dror et al., 2001.
   - Chapter 2.2 and 2.3 of Forsyth and Ponce, <a href="http://www.sci.utah.edu/~gerig/CS6320-S2012/Materials/Forsyth-Ponce-SfS.pdf">online here (Section 3.5 and 3.6)</a>
   - <a href="https://www.matthewtancik.com/nerf">NeRF</a>
  logistics:
   <span class="deadline">HW1 out (due 2/20)</span>

- date: 2/8
  lecturer: Grant
  title: <strong>Light and color</strong>
  readings:
  - Szeliski book, Chapter 2
  - Basic Color Terms &#58; Their Universality and Evolution, Berlin and Kay, 1969 (book, <a href="https://en.wikipedia.org/wiki/Basic_Color_Terms">Wikipedia article</a>)
  - <a href="https://www.ted.com/talks/beau_lotto_optical_illusions_show_how_we_see">Beau Lotto's TED talk</a>

- date: 2/9
  lecturer: Max, Fabien
  title: <strong>Python tutorial</strong> (Friday)
  readings:
  - <a href="https://colab.research.google.com/drive/1lYkyZDypN5Cm2a77Su60n39Hq0z3F4VA?usp=sharing">Collab page</a>
  logistics:
    <span class="deadline">CS 150/151</span>

- date: 2/13
  lecturer: Grant
  title: <strong>Light and color; Image formation</strong>
  readings:
  - Szeliski book, Chapter 2

- date: 2/15
  lecturer: Grant
  title: <strong>Image formation</strong>
  readings:
  - Szeliski book, Chapter 2
  - <a href="https://en.wikipedia.org/wiki/Camera">Wikipedia article on camera</a>
  - <a href="https://ict.usc.edu/research/projects/light-stages/">Light stages at USC</a>

- title: "Module 2: Basic Image Processing"

- date: 2/20
  lecturer: Grant
  title: <strong>Modeling images</strong>
  logistics:
   <span class="deadline">HW2 out (due 3/5)</span>
  readings:
  - <a href="https://people.eecs.berkeley.edu/~efros/research/EfrosLeung.html">Texture synthesis by non-parametric sampling</a>, Efros and Leung, 99
  - <a href="https://www.ipol.im/pub/art/2011/bcm_nlm/article.pdf">Non-local means denoising</a>, Buades et al., 11
  - OpenAI <a href="https://openai.com/dall-e-2/">DALL&#183;E 2</a> and <a href="https://openai.com/blog/gpt-3-apps/">GPT3</a>

- date: 2/22
  title: No class

- date: 2/27
  lecturer: Grant
  title: <strong>Linear filtering</strong>
  readings:
  - Szeliski book, Chaper 3
  - <a href="http://olivalab.mit.edu/hybridimage.htm">Hybrid images</a>
  - <a href="https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/">Berkeley segmentation dataset</a>

- title: "Module 3: Correspondence, Alignment, Geometry"

- date: 2/29
  lecturer: Grant
  title: <strong>Optical flow</strong>
  readings:
  - <a href="https://en.wikipedia.org/wiki/Lucas%E2%80%93Kanade_method">Lucas-Kanade optical flow</a>
  - <a href="https://vision.middlebury.edu/stereo/data/">Middlebury stereo dataset</a>
  - Szeliski book, Chapter 9

- date: 3/5
  lecturer: Grant
  title: >
       <strong>Feature detection and matching</strong>
  readings:
  - Szeliski book, Chapter 7.1

- date: 3/7
  lecturer: Grant
  title: <strong>Image transformations and alignment</strong>
  readings:
    - Szeliski book, Chapter 8.1

- date: 3/12
  lecturer: Grant
  title: <strong>Applications of image alignment</strong>
  readings:
    - Szeliski book, Chapter 8.2 & 11
    - <a href="https://www.robots.ox.ac.uk/~vgg/software/vise/">VGG image search</a>
  logistics:
   <span class="deadline">HW3 out (due 4/2)</span>

- title: "Module 4: Fundamentals of Neural Networks"

- date: 3/14
  lecturer: Grant
  title: <strong>Intro to recognition</strong>
  readings:
    - <a href="https://people.eecs.berkeley.edu/~efros/courses/AP06/Papers/csurka-eccv-04.pdf">Visual categorization with bag of keypoints</a>, Csurka et al., 2004
    - <a href="https://ieeexplore.ieee.org/document/1467360">Histogram of Oriented Gradients</a>, Dalal & Triggs, 2005
    - <a href="https://www.nature.com/articles/290091a0">Textons, the elements of texture perception, and their interactions</a>, Julesz, 1981
    - <a href="https://public.roboflow.com/">Computer vision datasets</a> (via Roboflow)

- date: 3/19
  title: No class (Spring recess)

- date: 3/21
  title: No class (Spring recess)

- date: 3/26
  lecturer: Grant, <i>remote</i>
  title: <strong>Project feedback</strong>

- date: 3/28
  lecturer: Grant, <i>remote</i>
  title: <strong>Project feedback</strong>

- date: 4/2
  lecturer: Grant
  title: <strong>Linear models</strong>
  readings:
    - <a href="https://link.springer.com/article/10.1007/BF02478259">Perceptron paper</a>, McColloch & Pitts, 1943
    - <a href="https://en.wikipedia.org/wiki/Linear_classifier">Linear classifier</a>, Wikipedia

- date: 4/4
  lecturer: Grant
  title: <strong>Neural networks</strong>
  readings:
    - <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=726791">LeNet</a>, <a href="https://dl.acm.org/doi/pdf/10.1145/3065386">AlexNet</a>
    - <a href="https://www.image-net.org/">ImageNet</a>
    - <a href="https://openai.com/blog/microscope/">OpenAI Microscope</a> (model visualizer)
    - <a href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html">Pytorch CNN tutorial</a>
- date: 4/9
  lecturer: Grant
  title: <strong>Neural networks</strong>
  logistics:
   <span class="deadline">HW4 out (due 5/2)</span>


- title: "Module 5: Advanced Topics in Recognition"

- date: 4/11
  lecturer: TBA
  title: <strong>TBA</strong>
  logistics: Guest lecture

- date: 4/16
  lecturer: Grant
  title: <strong>Transfer learning</strong>
  readings:
    - <a href="https://openaccess.thecvf.com/content_cvpr_workshops_2014/W15/papers/Razavian_CNN_Features_Off-the-Shelf_2014_CVPR_paper.pdf">CNNs off-the-shelf</a>, Razavian et al., 2014
    - <a href="https://openaccess.thecvf.com/content_cvpr_2015/html/Cimpoi_Deep_Filter_Banks_2015_CVPR_paper.html">Deep Filter Banks</a>, Cimpoi et al., 2015
    - <a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Lin_Bilinear_CNN_Models_ICCV_2015_paper.html">Bilinear CNNs</a>, Lin et al., 2015
    - <a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Zamir_Taskonomy_Disentangling_Task_CVPR_2018_paper.html">Taskonomy</a>, Zamir et al., 2018
    - <a href="https://openaccess.thecvf.com/content_ICCV_2019/html/Achille_Task2Vec_Task_Embedding_for_Meta-Learning_ICCV_2019_paper.html">Task2Vec</a>, Achille et al., 2019

- date: 4/18
  lecturer: Grant
  title: <strong>Object detection</strong>
  readings:
    - <a href="https://ieeexplore.ieee.org/abstract/document/1467360">Dalal & Triggs</a>, <a href="https://link.springer.com/chapter/10.1007/978-3-642-15567-3_13">Poselets</a>, <a href="https://link.springer.com/article/10.1007/s11263-013-0620-5">Selective search</a>
    - <a href="https://openaccess.thecvf.com/content_cvpr_2014/html/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.html">R-CNN</a>, <a href="https://openaccess.thecvf.com/content_iccv_2015/html/Girshick_Fast_R-CNN_ICCV_2015_paper.html">Fast R-CNN</a>, <a href="https://proceedings.neurips.cc/paper/2015/hash/14bfa6bb14875e45bba028a21ed38046-Abstract.html">Faster R-CNN</a>
    - <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Redmon_You_Only_Look_CVPR_2016_paper.html">YOLO</a>, <a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2">SSD</a>

- date: 4/23
  lecturer: Grant
  title: <strong>Object detection; Image segmentation</strong>
  readings:
    - <a href="https://openaccess.thecvf.com/content_iccv_2017/html/He_Mask_R-CNN_ICCV_2017_paper.html">Mask R-CNN</a>, He et al., ICCV 2017
    - <a href="https://openaccess.thecvf.com/content_cvpr_2015/html/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html">Fully convolutional networks</a>, Long & Shelhamer et al., CVPR 15
    - <a href="https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/">UNet</a>, Ronneberger et al., MICCAI 15
    - <a href="">Panoptic FCN</a>, Kirillov et al., CVPR 19

- date: 4/25
  lecturer: Grant
  title: <strong>Image generation</strong>
  readings:
    - <a href="https://arxiv.org/abs/1412.0035">Inverting deep representations</a>, Mahendran & Vedaldi, 2014
    - <a href="https://papers.nips.cc/paper/2015/hash/a5e00132373a7031000fd987a3c9f87b-Abstract.html">Texture synthesis & style transfer using CNNs</a>, Gatys et al., 2015
    - <a href="https://arxiv.org/abs/1603.03417">Texture networks</a>, Ulyanov et al., 2016
    - <a href="https://arxiv.org/abs/1511.05197">Visualizing deep texture representations</a>, Lin & Maji, 2016
    - <a href="https://dl.acm.org/doi/abs/10.1145/3422622">Generative adversarial networks</a>, Goodfellow et al., 2020 (CACM version)
    - <a href="https://dmitryulyanov.github.io/deep_image_prior">Deep image prior</a>, Ulyanov et al., 2017
    - Some theory on the deep image prior (DIP as a <a href="https://arxiv.org/abs/1904.07457">Gaussian process</a>, <a href="https://link.springer.com/article/10.1007/s11263-021-01572-7">Spectral bias</a> of DIP)

- date: 4/30
  lecturer: Grant
  title: <strong>Image generation</strong>

- date: 5/2
  lecturer: Grant
  title: <strong>Unsupervised learning</strong>
  readings:
    - Colorization -  <a href="https://arxiv.org/abs/1603.08511">Zhang et al., 2016</a>, <a href="https://arxiv.org/abs/1603.06668">Larsson et al., 2016</a>
    - Context prediction -  <a href="https://arxiv.org/abs/1505.05192">Doersch et al., 2015</a>
    - Jigsaw puzzle -  <a href="https://arxiv.org/abs/1603.09246">Noroozi & Favaro, 2016</a>
    - Image rotation - <a href="https://arxiv.org/abs/1803.07728">Gidaris et al., 2018</a>
    - Instance discrimination - <a href="https://proceedings.neurips.cc/paper/2014/hash/07563a3fe3bbe7e3ba84431ad9d055af-Abstract.html">Dosovitskiy et al., 2015</a>, <a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.html">Xu et al., 2018</a>, <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html">MOCO</a>, <a href="https://arxiv.org/abs/2002.05709">SimCLR</a>, <a href="https://arxiv.org/abs/2006.07733">BYOL</a>
    - 3D - <a href="https://link.springer.com/chapter/10.1007/978-3-030-58580-8_34">PointContrast</a>, <a href="https://link.springer.com/chapter/10.1007/978-3-030-58607-2_28">Convex Decomposition</a>
    - Audio -  <a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_48">Owens et al., 2016</a>
    - Video correspondence <a href="https://proceedings.neurips.cc/paper/2020/hash/e2ef524fbf3d9fe611d5a8e90fefdc9c-Abstract.html">Jabri et al., 2020</a>, Future prediction <a href="https://link.springer.com/chapter/10.1007/978-3-319-46478-7_51">Walker et al., 2016</a>
    - Generative modeling -  <a href="https://arxiv.org/abs/2103.04379">RepurposingGANs 2021</a>, <a href="https://arxiv.org/abs/2104.06490">DatasetGAN 2021</a>
    - Generative or Contrastive? <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Saha_GanOrCon_Are_Generative_Models_Useful_for_Few-Shot_Segmentation_CVPR_2022_paper.html">Saha et al., 22</a>

- date: 5/7
  lecturer: Grant
  title: <strong>Unsupervised learning</strong>

- date: 5/9
  lecturer: Grant
  title: <strong>3D shape understanding</strong>
  readings:
    - <a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Su_Multi-View_Convolutional_Neural_ICCV_2015_paper.html">Multi-view CNN</a>
    - <a href="https://ieeexplore.ieee.org/abstract/document/7353481">VoxNet</a>, <a href="https://dl.acm.org/doi/abs/10.1145/3072959.3073608">O-CNN</a>
    - <a href="https://openaccess.thecvf.com/content_cvpr_2017/html/Qi_PointNet_Deep_Learning_CVPR_2017_paper.html">PointNet</a>, <a href="https://proceedings.neurips.cc/paper/2017/hash/f22e4747da1aa27e363d86d40ff442fe-Abstract.html">Deep Sets</a>, <a href="https://proceedings.neurips.cc/paper/2017/hash/d8bf84be3800d12f74d8b05e9b89836f-Abstract.html">PointNet++</a>, <a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Su_SPLATNet_Sparse_Lattice_CVPR_2018_paper.html">SplatNet</a>
    - <a href="https://openaccess.thecvf.com/content_eccv_2018_workshops/w18/html/Su_A_Deeper_Look_at_3D_Shape_Classifiers_ECCVW_2018_paper.html">A deeper look at 3D classifiers</a>, Su et al. 18

- date: 5/10
  title: Poster presentations (CS 150/151) (Friday)
